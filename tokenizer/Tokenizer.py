import re

def tokenize(teks):
    words = [unit for unit in teks.split()]
    return words